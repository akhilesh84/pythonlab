{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import riskfolio as rp\n",
    "import math\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy.optimize import minimize\n",
    "import yfinance as yf\n",
    "from marketdatalib import map_scrip_to_yfin_ticker, get_nifty_index_data, calculate_beta\n",
    "import riskfolio as rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of year of historic data to consider\n",
    "YEARS_OF_HISTORY = 5\n",
    "\n",
    "# The risk free return rate. This is often the return on a 10 year government bond.\n",
    "# At present, the 10 year government bond rate is 6.84%. We are using 7.5% for the sake of simplicity which is the rate of a fixed deposit.\n",
    "RISK_FREE_RETURN = 0.075\n",
    "EXPECTED_MARKET_RETURN = 0.18\n",
    "ACCEPTABLE_VOLATILITY = 0.15\n",
    "\n",
    "# In intend to evaluate the performance of the portfolio, we will compare it with the performance of the benchmark index.\n",
    "BENCHMARK_INDEX_NIFTY500 = 'NIFTY%20500'\n",
    "\n",
    "scripts_to_ignore = ['SONACOMS']\n",
    "special_scrips = ['ARE&M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get benchmark data\n",
    "NIFTY500_DATA = get_nifty_index_data(index_name=BENCHMARK_INDEX_NIFTY500, number_of_years=YEARS_OF_HISTORY)\n",
    "NIFTY500_DATA.drop(columns=['Open', 'High', 'Low'], inplace=True)\n",
    "NIFTY500_DATA['NIFTY500_returns'] = NIFTY500_DATA['Close'].pct_change(fill_method=None)\n",
    "NIFTY500_DATA['NIFTY500_log_returns'] = NIFTY500_DATA['Close'].apply(lambda x: math.log(x)).diff()\n",
    "NIFTY500_DATA.dropna(inplace=True, axis=0)\n",
    "NIFTY500_DATA.rename(columns={'Close': 'NIFTY500'}, inplace=True)\n",
    "# NIFTY500_DATA[['Close', 'NIFTY500_returns', 'NIFTY500_log_returns']]\n",
    "NIFTY500_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I'll be running this exercise on my own portfolio, there are things that I need to hide before I commit the same to githud :-). So, assume that I have CSV of the stocks that I hold and I'll be using that to run this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings = pd.read_csv('../../data/MarketData/holdings.csv', names={'Instrument': 'Instrument', 'Quantity': 'Qty.', 'AvgCost': 'Avg. cost', 'LTP': 'LTP', 'CurVal': 'Cur. val', 'P&L': 'P&L', 'NetChg_Pct': 'Net chg.', 'DayChange_Pct': 'Day chg.', '':''}, header=0, index_col=0)\n",
    "holdings = holdings.loc[:, holdings.columns != '']\n",
    "\n",
    "indices_to_remove = [idx for idx in scripts_to_ignore if idx in holdings.index]\n",
    "holdings = holdings.drop(indices_to_remove, axis=0)\n",
    "\n",
    "holdings['Weight'] = holdings['CurVal'] / holdings['CurVal'].sum()\n",
    "\n",
    "portfolio_stocks = [map_scrip_to_yfin_ticker(scrip, 'NSE' if scrip not in special_scrips else 'BSE') for scrip in holdings.index]\n",
    "holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = pd.DataFrame()\n",
    "\n",
    "start_date = datetime.today() - relativedelta(years=YEARS_OF_HISTORY)\n",
    "\n",
    "scrips = [scrip for scrip, ticker in portfolio_stocks]\n",
    "assets = [ticker.ticker for _, ticker in portfolio_stocks]\n",
    "\n",
    "master_data = yf.download(assets, start = start_date)\n",
    "master_data = master_data.loc[:,('Adj Close', slice(None))]\n",
    "master_data.columns = scrips\n",
    "master_data.index = pd.to_datetime(master_data.index)\n",
    "master_data = master_data.sort_index()\n",
    "master_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encich_with_returns(data: pd.DataFrame):\n",
    "    for scrip, _ in portfolio_stocks:\n",
    "        data[scrip + '_returns'] = data[scrip].pct_change(fill_method=None)\n",
    "        data[scrip + '_log_returns'] = data[scrip].apply(lambda x: math.log(x)).diff()\n",
    "    data.dropna(inplace=True, axis=0)\n",
    "    return data\n",
    "\n",
    "master_data = encich_with_returns(master_data)\n",
    "master_data = pd.merge(master_data, NIFTY500_DATA, left_index=True, right_index=True)\n",
    "master_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point of time, we will compute a few portfolio specific statistics that are agnostic of weights of individual stocks in the poortfolio.\n",
    "- Coovariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matrix = master_data[[scrip + '_returns' for scrip in scrips]].cov().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realized_returns = pd.DataFrame(index=[scrip for scrip, _ in portfolio_stocks], columns=['Returns', 'AnnualizedReturns', 'DailyVolatility', 'AnnualizedVolatility', 'SharpeRatio', 'SortinoRatio', 'JensensAlpha', 'Beta'])\n",
    "\n",
    "market_std = master_data['NIFTY500_returns'].std()\n",
    "\n",
    "for scrip in scrips:\n",
    "    realized_returns.loc[scrip, 'Returns'] = (master_data[scrip + '_returns'] + 1).prod() - 1\n",
    "\n",
    "    # Calculate average daily return\n",
    "    avg_daily_return = np.mean(master_data[scrip + '_returns'])\n",
    "    annualized_return = (1 + avg_daily_return).mean() ** 252 - 1\n",
    "    # Calculate downside deviation\n",
    "    downside_returns = master_data[scrip + '_returns'][master_data[scrip + '_returns'] < 0]\n",
    "    downside_deviation = np.std(downside_returns)\n",
    "    annualized_downside_deviation = downside_deviation * np.sqrt(252)\n",
    "    daily_volatility = (master_data[scrip + '_returns']).std()\n",
    "    annualized_volatility = daily_volatility * math.sqrt(252)\n",
    "    beta = calculate_beta(master_data[scrip + '_returns'], master_data['NIFTY500_returns'])\n",
    "\n",
    "    realized_returns.loc[scrip, 'DailyVolatility'] = daily_volatility\n",
    "    annualized_std = realized_returns.loc[scrip, 'AnnualizedVolatility'] = annualized_volatility\n",
    "    realized_returns.loc[scrip, 'AnnualizedReturns'] = annualized_return\n",
    "    realized_returns.loc[scrip, 'SharpeRatio'] = (realized_returns.loc[scrip, 'AnnualizedReturns'] - RISK_FREE_RETURN) / annualized_std\n",
    "    \n",
    "    realized_returns.loc[scrip, 'Beta'] = beta\n",
    "    realized_returns.loc[scrip, 'ExpectedReturn'] = RISK_FREE_RETURN + beta * (EXPECTED_MARKET_RETURN - RISK_FREE_RETURN)\n",
    "\n",
    "    # Calculate Sortino Ratio\n",
    "    sortino_ratio = (annualized_return - RISK_FREE_RETURN) / annualized_downside_deviation\n",
    "\n",
    "    realized_returns.loc[scrip, 'SortinoRatio'] = sortino_ratio\n",
    "    # 'JensensAlpha'\n",
    "    # Calculate Jensen's Alpha\n",
    "    realized_returns.loc[scrip, 'JensensAlpha'] = realized_returns.loc[scrip, 'AnnualizedReturns'] - (RISK_FREE_RETURN + beta * (EXPECTED_MARKET_RETURN - RISK_FREE_RETURN))\n",
    "\n",
    "realized_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table represents the the statistics associated with each of the security in our portfolio. The benchmark index that we're using for calculations is the NIFTY 500 TRI index. The expected return above is based on the current weightage of each of the security in the portfolio.\n",
    "\n",
    "- The expected return is calculated by multiplying the weightage of each security with the expected return of the security.\n",
    "- The Sharpe ratio of the portfolio is calculated by dividing the expected return of the portfolio by the standard deviation of the portfolio. The Sharpe ratio of the portfolio is used to calculate the risk-adjusted return of the portfolio.\n",
    "- The risk-adjusted return of the portfolio is calculated by multiplying the Sharpe ratio of the portfolio with the expected return of the portfolio. The risk-adjusted return of the portfolio is used to calculate the risk-adjusted return of each security. The risk-adjusted return of each security is calculated by multiplying the Sharpe ratio of the portfolio with the expected return of the security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_expected_return = holdings['Weight'].dot(realized_returns['ExpectedReturn'])\n",
    "\n",
    "weights = holdings['Weight']\n",
    "\n",
    "portfolio_variance = np.dot(weights.T, np.dot(covariance_matrix, weights))\n",
    "\n",
    "# Calculate the portfolio standard deviation (volatility)\n",
    "portfolio_std_dev = np.sqrt(portfolio_variance)\n",
    "\n",
    "# Calculate the Sharpe Ratio\n",
    "portfolio_sharpe_ratio = (portfolio_expected_return - RISK_FREE_RETURN) / portfolio_std_dev\n",
    "\n",
    "print('Expected Portfolio Return: {0:.2f}%'.format(portfolio_expected_return * 100))\n",
    "print('Expected Portfolio Volatility: {0:.2f}%'.format(portfolio_std_dev * 100))\n",
    "print('Sharpe Ratio of Portfolio: {0:.2f}'.format(portfolio_sharpe_ratio))\n",
    "print('Risk adjusted return of Portfolio: {0:.2f}'.format(portfolio_sharpe_ratio * portfolio_expected_return))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One extremely important factor that we need to keep in mind is that for the sake of simplicity and for lack of data, we've only considered the last 5 years of benchmark data. This is going to hide the fact that the market might have given an extremely high return in the last 5 years (specially after COVID) and the expected return of the portfolio might not be replicable in the coming future. This is a limitation of the model and we need to keep this in mind while making any investment decisions based on the model.\n",
    "\n",
    "This is also the reason why we've considered an error of 5% in the expected return of the portfolio. i.e., we are assuming that the expected rate of return of the portfolio can be 5% lower than the expected rate of return that we've calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Optimization\n",
    "\n",
    "In the next section, we are going to try and optimize the portfolio. The purpose of this exercise is basically to find the optimal weights of each security in the portfolio such that the portfolio has the highest Sharpe ratio. i.e., maximize risk adjusted returns foor a given level of risk.\n",
    "\n",
    "I'm going to make use of a library called riskfolio-lib to optimize the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the expected returns and volatilities for each security\n",
    "# correlation_matrix = master_data[[scrip + '_returns' for scrip, _ in portfolio_stocks]].corr().to_numpy()\n",
    "securities = [scrip for scrip in scrips]\n",
    "expected_returns = realized_returns['ExpectedReturn'].to_numpy()\n",
    "volatilities = realized_returns['DailyVolatility'].to_numpy()\n",
    "\n",
    "# Step 2: Calculate the covariance matrix\n",
    "cov_matrix = covariance_matrix\n",
    "# cov_matrix = np.outer(volatilities, volatilities) * correlation_matrix\n",
    "\n",
    "# Step 3: Generate random portfolios\n",
    "num_portfolios = 1000\n",
    "results = np.zeros((3, num_portfolios))\n",
    "\n",
    "for i in range(num_portfolios):\n",
    "    weights = np.random.random(len(securities))\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    portfolio_return = np.dot(weights, expected_returns)\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    \n",
    "    results[0,i] = portfolio_return\n",
    "    results[1,i] = portfolio_volatility\n",
    "    results[2,i] = results[0,i] / results[1,i]  # Sharpe Ratio\n",
    "\n",
    "# Step 4: Plot the efficient frontier\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(results[1,:], results[0,:], c=results[2,:], cmap='viridis')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Return')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll compute the capital allocation line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of securities\n",
    "num_securities = len(securities)\n",
    "\n",
    "# Define the objective function to minimize (negative Sharpe ratio)\n",
    "def objective(weights):\n",
    "    portfolio_return = np.dot(weights, expected_returns)\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    sharpe_ratio = portfolio_return / portfolio_volatility\n",
    "    return -sharpe_ratio\n",
    "\n",
    "# Define the constraint for acceptable volatility\n",
    "def volatility_constraint(weights):\n",
    "    return ACCEPTABLE_VOLATILITY - np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "\n",
    "# Define the constraints and bounds\n",
    "constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},\n",
    "               {'type': 'ineq', 'fun': volatility_constraint})\n",
    "bounds = tuple((0, 1) for _ in range(num_securities))\n",
    "\n",
    "# Initial guess for the weights\n",
    "initial_guess = num_securities * [1. / num_securities]\n",
    "\n",
    "# Perform the optimization\n",
    "result = minimize(objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "# Get the optimal weights\n",
    "optimal_weights = result.x\n",
    "\n",
    "# Calculate the expected return and volatility of the optimal risky portfolio\n",
    "optimal_portfolio_return = np.dot(optimal_weights, expected_returns)\n",
    "optimal_portfolio_volatility = np.sqrt(np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights)))\n",
    "\n",
    "# Generate the Capital Allocation Line (CAL)\n",
    "cal_returns = []\n",
    "cal_volatilities = []\n",
    "\n",
    "for weight in np.linspace(0, 1.5, 100):\n",
    "    cal_return = RISK_FREE_RETURN + weight * (optimal_portfolio_return - RISK_FREE_RETURN)\n",
    "    cal_volatility = weight * optimal_portfolio_volatility\n",
    "    cal_returns.append(cal_return)\n",
    "    cal_volatilities.append(cal_volatility)\n",
    "\n",
    "# Plot the CAL\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cal_volatilities, cal_returns, label='Capital Allocation Line (CAL)')\n",
    "plt.scatter(optimal_portfolio_volatility, optimal_portfolio_return, color='red', marker='*', s=100, label='Optimal Risky Portfolio')\n",
    "plt.xlabel('Volatility (Standard Deviation)')\n",
    "plt.ylabel('Expected Return')\n",
    "plt.title('Capital Allocation Line (CAL)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fund, pct_allocation in zip(scrips, optimal_weights):\n",
    "    print('\\t{0}: {1:.2f}%'.format(fund, pct_allocation * 100))\n",
    "    \n",
    "print('\\n\\nExpected Portfolio Return: {0:.2f}%'.format(np.dot(optimal_weights, expected_returns) * 100))\n",
    "print('Expected Portfolio Volatility: {0:.2f}%'.format(optimal_portfolio_volatility * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the CAL and the efficient frontier\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(results[1, :], results[0, :], c=results[2, :], cmap='viridis', marker='o', s=10, alpha=0.3, label='Efficient Frontier')\n",
    "plt.plot(cal_volatilities, cal_returns, label='Capital Allocation Line (CAL)', color='red')\n",
    "plt.scatter(optimal_portfolio_volatility, optimal_portfolio_return, color='blue', marker='*', s=100, label='Optimal Risky Portfolio')\n",
    "plt.xlabel('Volatility (Standard Deviation)')\n",
    "plt.ylabel('Expected Return')\n",
    "plt.title('Efficient Frontier and Capital Allocation Line (CAL)')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1438, 64), (1438,), (359, 64), (359,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = datasets.load_digits(return_X_y=False, as_frame=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# X_train.shape, y_train.shape\n",
    "percentage = 0.8\n",
    "\n",
    "# Get the index of the records that will be used for training. i.e. 80% of the data for training. The remaining will be used for testing\n",
    "index_ = df.data.sample(frac=percentage, random_state=76).index\n",
    "X_train = df.data.iloc[index_]\n",
    "y_train = df.target.iloc[index_]\n",
    "\n",
    "X_test = df.data.drop(index_)\n",
    "y_test = df.target.drop(index_)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 logistic : 95.26%\n",
      "Micro-Averaged Precision: 0.95\n",
      "Micro-Averaged Recall: 0.95\n",
      "Macro-Averaged Precision: 0.95\n",
      "Macro-Averaged Recall: 0.95\n",
      "Weighted-Averaged Precision: 0.96\n",
      "Weighted-Averaged Recall: 0.95\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        38\n",
      "           1       0.81      0.96      0.88        26\n",
      "           2       0.97      1.00      0.99        36\n",
      "           3       1.00      0.90      0.95        40\n",
      "           4       0.97      0.94      0.96        34\n",
      "           5       0.90      0.97      0.93        29\n",
      "           6       1.00      0.98      0.99        43\n",
      "           7       1.00      0.95      0.97        40\n",
      "           8       0.90      0.90      0.90        39\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.95       359\n",
      "   macro avg       0.95      0.95      0.95       359\n",
      "weighted avg       0.96      0.95      0.95       359\n",
      "\n",
      "\n",
      "======================================================\n",
      "\n",
      "L2 logistic (Multinomial) : 95.54%\n",
      "Micro-Averaged Precision: 0.96\n",
      "Micro-Averaged Recall: 0.96\n",
      "Macro-Averaged Precision: 0.95\n",
      "Macro-Averaged Recall: 0.96\n",
      "Weighted-Averaged Precision: 0.96\n",
      "Weighted-Averaged Recall: 0.96\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        38\n",
      "           1       0.81      0.96      0.88        26\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.97      0.93      0.95        40\n",
      "           4       0.97      0.94      0.96        34\n",
      "           5       0.91      1.00      0.95        29\n",
      "           6       1.00      0.98      0.99        43\n",
      "           7       1.00      0.93      0.96        40\n",
      "           8       0.90      0.90      0.90        39\n",
      "           9       0.97      0.97      0.97        34\n",
      "\n",
      "    accuracy                           0.96       359\n",
      "   macro avg       0.95      0.96      0.95       359\n",
      "weighted avg       0.96      0.96      0.96       359\n",
      "\n",
      "\n",
      "======================================================\n",
      "\n",
      "L2 logistic (OvR) : 93.87%\n",
      "Micro-Averaged Precision: 0.94\n",
      "Micro-Averaged Recall: 0.94\n",
      "Macro-Averaged Precision: 0.94\n",
      "Macro-Averaged Recall: 0.94\n",
      "Weighted-Averaged Precision: 0.94\n",
      "Weighted-Averaged Recall: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        38\n",
      "           1       0.81      0.85      0.83        26\n",
      "           2       1.00      0.97      0.99        36\n",
      "           3       0.90      0.93      0.91        40\n",
      "           4       1.00      0.94      0.97        34\n",
      "           5       0.88      0.97      0.92        29\n",
      "           6       0.98      1.00      0.99        43\n",
      "           7       0.95      0.97      0.96        40\n",
      "           8       0.89      0.85      0.87        39\n",
      "           9       0.94      0.94      0.94        34\n",
      "\n",
      "    accuracy                           0.94       359\n",
      "   macro avg       0.94      0.94      0.94       359\n",
      "weighted avg       0.94      0.94      0.94       359\n",
      "\n",
      "\n",
      "======================================================\n",
      "\n",
      "Linear SVC : 97.49%\n",
      "Micro-Averaged Precision: 0.97\n",
      "Micro-Averaged Recall: 0.97\n",
      "Macro-Averaged Precision: 0.97\n",
      "Macro-Averaged Recall: 0.98\n",
      "Weighted-Averaged Precision: 0.98\n",
      "Weighted-Averaged Recall: 0.97\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       0.83      0.96      0.89        26\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       1.00      0.97      0.99        40\n",
      "           4       0.97      0.97      0.97        34\n",
      "           5       0.97      1.00      0.98        29\n",
      "           6       1.00      0.98      0.99        43\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.95      0.90      0.92        39\n",
      "           9       1.00      0.97      0.99        34\n",
      "\n",
      "    accuracy                           0.97       359\n",
      "   macro avg       0.97      0.98      0.97       359\n",
      "weighted avg       0.98      0.97      0.98       359\n",
      "\n",
      "\n",
      "======================================================\n",
      "\n",
      "Ridge Classifier : 91.09%\n",
      "Micro-Averaged Precision: 0.91\n",
      "Micro-Averaged Recall: 0.91\n",
      "Macro-Averaged Precision: 0.91\n",
      "Macro-Averaged Recall: 0.91\n",
      "Weighted-Averaged Precision: 0.91\n",
      "Weighted-Averaged Recall: 0.91\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        38\n",
      "           1       0.75      0.92      0.83        26\n",
      "           2       0.89      0.86      0.87        36\n",
      "           3       0.92      0.90      0.91        40\n",
      "           4       1.00      0.85      0.92        34\n",
      "           5       0.90      0.97      0.93        29\n",
      "           6       0.98      0.98      0.98        43\n",
      "           7       0.91      0.97      0.94        40\n",
      "           8       0.89      0.79      0.84        39\n",
      "           9       0.88      0.88      0.88        34\n",
      "\n",
      "    accuracy                           0.91       359\n",
      "   macro avg       0.91      0.91      0.91       359\n",
      "weighted avg       0.91      0.91      0.91       359\n",
      "\n",
      "\n",
      "======================================================\n",
      "\n",
      "SGD Classifier : 93.87%\n",
      "Micro-Averaged Precision: 0.94\n",
      "Micro-Averaged Recall: 0.94\n",
      "Macro-Averaged Precision: 0.94\n",
      "Macro-Averaged Recall: 0.94\n",
      "Weighted-Averaged Precision: 0.94\n",
      "Weighted-Averaged Recall: 0.94\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        38\n",
      "           1       0.77      0.92      0.84        26\n",
      "           2       1.00      0.97      0.99        36\n",
      "           3       0.97      0.90      0.94        40\n",
      "           4       0.97      0.91      0.94        34\n",
      "           5       0.88      1.00      0.94        29\n",
      "           6       1.00      0.98      0.99        43\n",
      "           7       1.00      0.90      0.95        40\n",
      "           8       0.83      0.90      0.86        39\n",
      "           9       0.97      0.94      0.96        34\n",
      "\n",
      "    accuracy                           0.94       359\n",
      "   macro avg       0.94      0.94      0.94       359\n",
      "weighted avg       0.94      0.94      0.94       359\n",
      "\n",
      "\n",
      "======================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = 10\n",
    "kernel = 1.0 * RBF([1.0, 1.0])  # for GPC\n",
    "\n",
    "classifiers = {\n",
    "    \"L1 logistic\": linear_model.LogisticRegression(C=C, penalty=\"l1\", solver=\"saga\", max_iter=10000),\n",
    "    \"L2 logistic (Multinomial)\": linear_model.LogisticRegression(C=C, penalty=\"l2\", solver=\"saga\", max_iter=10000),\n",
    "    \"L2 logistic (OvR)\": OneVsRestClassifier(linear_model.LogisticRegression(C=C, penalty=\"l2\", solver=\"saga\", max_iter=10000)),\n",
    "    \"Linear SVC\": SVC(kernel=\"linear\", C=C, probability=True, random_state=0),\n",
    "    \"Ridge Classifier\": linear_model.RidgeClassifier(),\n",
    "    \"SGD Classifier\": linear_model.SGDClassifier(max_iter=1000, tol=1e-3, loss=\"hinge\", penalty=\"l2\")\n",
    "}\n",
    "\n",
    "for classifier_idx, (name, model) in enumerate(classifiers.items()):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_predicted = model.predict(X_test)\n",
    "\n",
    "    score = accuracy_score(y_test, y_predicted)\n",
    "    print(\"{} : {:.2f}%\".format(name, score*100))\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision_micro = precision_score(y_test, y_predicted, average='micro')\n",
    "    recall_micro = recall_score(y_test, y_predicted, average='micro')\n",
    "\n",
    "    precision_macro = precision_score(y_test, y_predicted, average='macro')\n",
    "    recall_macro = recall_score(y_test, y_predicted, average='macro')\n",
    "\n",
    "    precision_weighted = precision_score(y_test, y_predicted, average='weighted')\n",
    "    recall_weighted = recall_score(y_test, y_predicted, average='weighted')\n",
    "\n",
    "    print(f\"Micro-Averaged Precision: {precision_micro:.2f}\")\n",
    "    print(f\"Micro-Averaged Recall: {recall_micro:.2f}\")\n",
    "\n",
    "    print(f\"Macro-Averaged Precision: {precision_macro:.2f}\")\n",
    "    print(f\"Macro-Averaged Recall: {recall_macro:.2f}\")\n",
    "\n",
    "    print(f\"Weighted-Averaged Precision: {precision_weighted:.2f}\")\n",
    "    print(f\"Weighted-Averaged Recall: {recall_weighted:.2f}\")\n",
    "\n",
    "    # Detailed classification report\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_predicted, labels=df.target_names))\n",
    "    print(\"\\n======================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
